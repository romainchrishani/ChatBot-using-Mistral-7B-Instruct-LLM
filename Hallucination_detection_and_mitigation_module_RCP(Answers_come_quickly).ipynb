{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "1wVlSvPDBWSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install sentence-transformers\n",
        "!pip install streamlit\n",
        "!pip install streamlit-chat\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install huggingface-hub\n",
        "!pip install pypdf\n",
        "!pip install llama-cpp-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txc1fUi4BTRb",
        "outputId": "9849cfe8-82bf-41d2-de0a-92755faf2f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n",
            "  Downloading langchain_core-0.2.8-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.79-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.8 langchain-text-splitters-0.2.1 langsmith-0.1.79 orjson-3.10.5\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GPIJl-J5Uji",
        "outputId": "933f0fce-d06e-4e89-f6a7-6e57f4b6fb7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.7)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.5 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import os\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "-hJcbCRnvcdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_session_state():\n",
        "    session_state = {\n",
        "        \"history\": [],\n",
        "        \"generated\": [\"Hello! Ask me anything about ü§ñ\"],\n",
        "        \"past\": [\"Hey! üëã\"]\n",
        "    }\n",
        "    return session_state\n"
      ],
      "metadata": {
        "id": "qoc_B25FxlQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conversation_chat(query, chain, session_state):\n",
        "    result = chain({\"question\": query, \"chat_history\": session_state[\"history\"]})\n",
        "    session_state[\"history\"].append((query, result[\"answer\"]))\n",
        "    return result[\"answer\"]\n"
      ],
      "metadata": {
        "id": "Kin1WViBxyol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_chat_history(chain, session_state):\n",
        "    user_input = input(\"Enter your question: \")\n",
        "    if not user_input:\n",
        "        return\n",
        "\n",
        "    print(f\"Repeating question '{user_input}' 10 times:\")\n",
        "\n",
        "    for _ in range(10):\n",
        "        output = conversation_chat(user_input, chain, session_state)\n",
        "        print(\"Bot:\", output)\n",
        "\n"
      ],
      "metadata": {
        "id": "8riu7D9lyEU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import DeepInfra\n"
      ],
      "metadata": {
        "id": "dtAZAvZS5zJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DEEPINFRA_API_TOKEN\"] = \"ohnGw99RAl4ZyJ6zI8gb7RpMGEZ30yHt\""
      ],
      "metadata": {
        "id": "xfU0QoNk2k8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import DeepInfra\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "def create_conversational_chain(vector_store):\n",
        "    local_llm = DeepInfra(model_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "        #streaming=True,\n",
        "        #temperature=0.75,\n",
        "        #top_p=1,\n",
        "        #verbose=True,\n",
        "        #n_ctx=4096,\n",
        "    )\n",
        "\n",
        "    local_llm.model_kwargs = {\n",
        "        \"streaming\":True,\n",
        "        \"temperature\": 0.75,\n",
        "        \"top_p\":1,\n",
        "        \"verbose\":True,\n",
        "        \"n_ctx\" : 4096,\n",
        "    }\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=local_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
        "        memory=memory\n",
        "    )\n",
        "    return chain"
      ],
      "metadata": {
        "id": "8RW_HxWO9P1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    session_state=initialize_session_state()\n",
        "    print(\"ChatBot using Mistral-7B-Instruct LLM :books:\")\n",
        "\n",
        "    uploaded_files = [\"/content/University2.pdf\"]\n",
        "\n",
        "    if uploaded_files:\n",
        "        text = []\n",
        "        for file_path in uploaded_files:\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                file_contents = f.read()\n",
        "            file_extension = os.path.splitext(file_path)[1]\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "                temp_file.write(file_contents)\n",
        "                temp_file_path = temp_file.name\n",
        "                print(\"loading: \", file_path)\n",
        "            loader = None\n",
        "            if file_extension == \".pdf\":\n",
        "                loader = PyPDFLoader(temp_file_path)\n",
        "\n",
        "            if loader:\n",
        "                text.extend(loader.load())\n",
        "                os.remove(temp_file_path)\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=10000, chunk_overlap=20\n",
        "        )\n",
        "        text_chunks = text_splitter.split_documents(text)\n",
        "\n",
        "        print(\"chunks:\\n\", text_chunks)\n",
        "\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            model_kwargs={\"device\": \"cpu\"},\n",
        "        )\n",
        "\n",
        "        print(\"embeddings:\\n\", embeddings)\n",
        "\n",
        "        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n",
        "\n",
        "        chain = create_conversational_chain(vector_store)\n",
        "\n",
        "        display_chat_history(chain,session_state)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a536fda7-a08f-4afb-b23c-d54845ebe948",
        "id": "fH2OBuVUxnpH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatBot using Mistral-7B-Instruct LLM :books:\n",
            "loading:  /content/University2.pdf\n",
            "chunks:\n",
            " [Document(page_content='The Faculty of Information Technology is the youngest of the three faculties of the  University \\nof Moratuwa  and is the first ever faculty of its kind in the national university system of Sri \\nLanka. The Faculty was established in June 2001 to cater to the growing need of Information \\nTechnology professionals in the country. Presently, the Faculty conducts two int ernal degree \\nprogrammes, namely,  B.Sc. (Hons.) in Information Technology  and B.Sc. (Hons.) in Information \\nTechnology & Management , and the  Bachelor of Information Technology , the external degree \\nprogramme.  \\n \\nOne of the main objectives of setting up the faculty is to increase the number of IT \\nprofessionals in Sri Lanka by at least another 500. Some of the other objectives defined during \\nthe establishment of the faculty are the introduction of postgraduate progr ammes, carrying \\nout research programmes for the industry in order to solve technical problems, providing \\nconsultancies to the local industry and creating an educational environment for the continuous \\nprofessional development of IT professionals in Sri Lank a. \\n \\nThirteen batches of students have been admitted to the Faculty for the internal undergraduate \\nprogramme and out of these, 9 batches have already passed out after completing their studies \\nsuccessfully. The Faculty is conducting a  Master of Science in Information \\nTechnology , Masters of Science in Artificial Intelligence , Master of Philosophy and Doctoral \\ndegrees  as postgraduate programmes starting from early 2004. Also, a few professional \\ndevelopment programmes have been designed to address the immediate needs of the local IT \\nindustry. The current undergraduate student population is about 600.  \\nThe Faculty is committed to continue to develop and expand its activities catering to the ever \\nchanging needs of the IT industry and to become an entity which both the students and the \\nindustry would look up to.   \\n \\nThe faculty consists of three departments of study, and each department is managed by the \\nrespective Head of Department. The three departments are,   \\n‚Ä¢ Department of Information Technology  \\n‚Ä¢ Department of Computational Mathematics  \\n‚Ä¢ Department of Interdisciplinary Studies  \\nPresently, the departments collaboratively offer subjects for the degree programmes \\nconducted by the Faculty. The relevant subjects of the programmes have been allocated \\namong the three departments.  Further, for the administrative purposes of the undergrad uate \\nand postgraduate programmes, two divisions have been established with each division headed \\nby a director. The Undergraduate Studies Division presently handles matters pertaining the \\nacademic affairs of the undergraduate study programmes of the Faculty . Students attendance \\nmonitoring and student feedback administration are also carried out by this Division. Matters \\npertaining to taught postgraduate programmes and research degrees are handled by the \\nPostgraduate Studies Division.', metadata={'source': '/tmp/tmpbocv1gho', 'page': 0})]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings:\n",
            " client=SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ") model_name='sentence-transformers/all-MiniLM-L6-v2' cache_folder=None model_kwargs={'device': 'cpu'} encode_kwargs={} multi_process=False show_progress=False\n",
            "Enter your question: what are the three departments?\n",
            "Repeating question 'what are the three departments?' 10 times:\n",
            "Bot:  The three departments are Department of Information Technology, Department of Computational Mathematics, and Department of Interdisciplinary Studies.\n",
            "Bot:   The Faculty of Information Technology in the University of Moratuwa  has three \n",
            "departments of study, namely, Department of Information Technology , Department of Computational \n",
            "Mathematics , and Department of Interdisciplinary Studies. These departments collaboratively \n",
            "offer subjects for the degree programmes conducted by the Faculty.\n",
            "Bot:   The three departments of the Faculty of Information Technology in the University of Moratuwa are the Department of Information Technology, the Department of Computational Mathematics, and the Department of Interdisciplinary Studies.\n",
            "Bot:  The three departments in the Faculty of Information Technology are the Department of Information Technology, Department of Computational Mathematics, and Department of Interdisciplinary Studies.\n",
            "Bot:   The three departments in the Faculty of Information Technology at the University of Moratuwa are Department of Information Technology, Department of Computational Mathematics, and Department of Interdisciplinary Studies.\n",
            "Bot:  Sure, the three departments in the Faculty of Information Technology at the University of Moratuwa are the Department of Information Technology, the Department of Computational Mathematics, and the Department of Interdisciplinary Studies.\n",
            "Bot:   The three departments in the Faculty of Information Technology at the University of Moratuwa are the Department of Information Technology, the Department of Computational Mathematics, and the Department of Interdisciplinary Studies.\n",
            "Bot:  The three departments in the Faculty of Information Technology at the University of Moratuwa are Department of Information Technology, Department of Computational Mathematics, and Department of Interdisciplinary Studies.\n",
            "Bot:  The three departments in the Faculty of Information Technology at the University of Moratuwa are the Department of Information Technology, the Department of Computational Mathematics, and the Department of Interdisciplinary Studies.\n",
            "Bot:   The three departments available in the Faculty of Information Technology at the University of Moratuwa are, Department of Information Technology, Department of Computational Mathematics, and Department of Interdisciplinary Studies.\n",
            "\n",
            "We were told that they have collaboratively offered subjects for the degree programmes and that also the relevant subjects of the programmes have been allocated among the three departments. We also know that for administrative purposes two divisions have been established, Undergraduate Studies Division and Postgraduate Studies Division, and each division is headed by a director. The Undergraduate Studies Division handles matters pertaining the academic affairs of the undergraduate study programmes of the Faculty, while the Postgraduate Studies Division handles matters pertaining to taught postgraduate programmes and research degrees.\n"
          ]
        }
      ]
    }
  ]
}