{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "526f72f8a762415386ee7f65b00e2220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_651976157e0b4affa9360df86c41e83e",
              "IPY_MODEL_5216909494644f38ab3c2b7c19f7bd36",
              "IPY_MODEL_1d5c03dcb07c45918057aea41f35b085"
            ],
            "layout": "IPY_MODEL_88a93573daa949d0bf542ea7d0c3cd6f"
          }
        },
        "651976157e0b4affa9360df86c41e83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c080aea91ca44b48623cdb97c319641",
            "placeholder": "​",
            "style": "IPY_MODEL_eaeb9443ce3c40ec861c1f251b090f9a",
            "value": "modules.json: 100%"
          }
        },
        "5216909494644f38ab3c2b7c19f7bd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3e9013708c43b6b8f19cb98d3250b5",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_556ade52b6a44cee8fa02713727116af",
            "value": 349
          }
        },
        "1d5c03dcb07c45918057aea41f35b085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cdd902c9dae45daba00748b3be7afb6",
            "placeholder": "​",
            "style": "IPY_MODEL_1633308f46974da79004a67f2aaf92cd",
            "value": " 349/349 [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "88a93573daa949d0bf542ea7d0c3cd6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c080aea91ca44b48623cdb97c319641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaeb9443ce3c40ec861c1f251b090f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d3e9013708c43b6b8f19cb98d3250b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556ade52b6a44cee8fa02713727116af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cdd902c9dae45daba00748b3be7afb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1633308f46974da79004a67f2aaf92cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b406cd9cc1b94d3aa7a4e8b5e885845e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_470c48fd14934b4fa6fb40902752a0d8",
              "IPY_MODEL_8580e4d5529449968621615ba8aa0e23",
              "IPY_MODEL_a476a1110fdd4b64b0634add1e42f5bd"
            ],
            "layout": "IPY_MODEL_d981bd58d4c74ec489515234585a962d"
          }
        },
        "470c48fd14934b4fa6fb40902752a0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a35c6356c74817a53a7fbff42dd9b0",
            "placeholder": "​",
            "style": "IPY_MODEL_5659025d30b44ce696706836288318e8",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "8580e4d5529449968621615ba8aa0e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2431f19a166b49e4a4204ef904d3daf7",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fbf251af2774b4eb11a2bd6da48b239",
            "value": 116
          }
        },
        "a476a1110fdd4b64b0634add1e42f5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc34ce12a4d4f7582a3fc0441b5fe63",
            "placeholder": "​",
            "style": "IPY_MODEL_93d2e6725e7d49978d1114251827de9a",
            "value": " 116/116 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "d981bd58d4c74ec489515234585a962d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a35c6356c74817a53a7fbff42dd9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5659025d30b44ce696706836288318e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2431f19a166b49e4a4204ef904d3daf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbf251af2774b4eb11a2bd6da48b239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bc34ce12a4d4f7582a3fc0441b5fe63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d2e6725e7d49978d1114251827de9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8ea16c7f42450a8e7d6824ed59ff44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4169a801e0540b4a447814ee163f3a7",
              "IPY_MODEL_fbb33b5232b2479195bd64bebf3f5540",
              "IPY_MODEL_3d05d51e8f3b4c9e9c5d88ec975ef3ba"
            ],
            "layout": "IPY_MODEL_53993729526e48749c36b928eb083dac"
          }
        },
        "a4169a801e0540b4a447814ee163f3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3babdfcf2142b593364084295a08ed",
            "placeholder": "​",
            "style": "IPY_MODEL_072996917f8a434e92a3f8de90e66d14",
            "value": "README.md: 100%"
          }
        },
        "fbb33b5232b2479195bd64bebf3f5540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd50d7fa5a40489cbd60ef2eacf0e6b9",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_646112f2138d40caa0223af726611ec3",
            "value": 10659
          }
        },
        "3d05d51e8f3b4c9e9c5d88ec975ef3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4743f2eca90346b0b91a55afb82c6a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_a682b9bf5d7446e79ad91e8ca0e7ee79",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 880kB/s]"
          }
        },
        "53993729526e48749c36b928eb083dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3babdfcf2142b593364084295a08ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072996917f8a434e92a3f8de90e66d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd50d7fa5a40489cbd60ef2eacf0e6b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646112f2138d40caa0223af726611ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4743f2eca90346b0b91a55afb82c6a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a682b9bf5d7446e79ad91e8ca0e7ee79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e50284106c44c269b6e6f641d0d507c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f31bf6b08d64c5ca5a6dd388ba129bd",
              "IPY_MODEL_f19ef990430e49bab720d7d0494596e4",
              "IPY_MODEL_b5c617d3bfd8498794866eb4f68d9924"
            ],
            "layout": "IPY_MODEL_0283ea89785f4c289309bde22e4f6b83"
          }
        },
        "6f31bf6b08d64c5ca5a6dd388ba129bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2ed41d669342c3860cb629a75a4653",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3b9ba6af664ae6b37c6398a2f6ef69",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "f19ef990430e49bab720d7d0494596e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7238e8d96a324a93b2eb81baa4a2ca5c",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7461bb5edfe4c2d9f71c2d666603225",
            "value": 53
          }
        },
        "b5c617d3bfd8498794866eb4f68d9924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfdc8d654434f8985b18e5ed5d838c3",
            "placeholder": "​",
            "style": "IPY_MODEL_be87d5c28e104e17bcfa0a1014f07da2",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.21kB/s]"
          }
        },
        "0283ea89785f4c289309bde22e4f6b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2ed41d669342c3860cb629a75a4653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3b9ba6af664ae6b37c6398a2f6ef69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7238e8d96a324a93b2eb81baa4a2ca5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7461bb5edfe4c2d9f71c2d666603225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cfdc8d654434f8985b18e5ed5d838c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be87d5c28e104e17bcfa0a1014f07da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0bf037b7ee44faaaff7d929ef86f53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3ce12f47224705bd340f2b32620787",
              "IPY_MODEL_5ae694d8ea0f4af7b9f65aaccfb5f68c",
              "IPY_MODEL_c98835d0cd8b44cc851ba8cb9049d471"
            ],
            "layout": "IPY_MODEL_200986e6cb21406db5c47d22389debb3"
          }
        },
        "1e3ce12f47224705bd340f2b32620787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221d37413b984973a592449313440ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_82e3dd09ca3f4ccaa77ae07011f8c39e",
            "value": "config.json: 100%"
          }
        },
        "5ae694d8ea0f4af7b9f65aaccfb5f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b13904a0d9b4fd99170e3a8ef7f9159",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f45624075d1e43e1ad7bf44f3abdadf0",
            "value": 612
          }
        },
        "c98835d0cd8b44cc851ba8cb9049d471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f8e8d06ee741c3ad5c9e9280465815",
            "placeholder": "​",
            "style": "IPY_MODEL_533433ca6707490aa671a9b7d1f2c239",
            "value": " 612/612 [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "200986e6cb21406db5c47d22389debb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221d37413b984973a592449313440ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e3dd09ca3f4ccaa77ae07011f8c39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b13904a0d9b4fd99170e3a8ef7f9159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45624075d1e43e1ad7bf44f3abdadf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52f8e8d06ee741c3ad5c9e9280465815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533433ca6707490aa671a9b7d1f2c239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6915cf41bd6a4ab7b03b00d59c028f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d917a1c5caaa41ea9d152ccd123e0fda",
              "IPY_MODEL_bbf0ae8c8d3649b38941fed8c0f044ed",
              "IPY_MODEL_1ad921c23417401b9e2eca55a81495d5"
            ],
            "layout": "IPY_MODEL_f6e29d143ad240c9b5e91dfcd776f0b7"
          }
        },
        "d917a1c5caaa41ea9d152ccd123e0fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3dbc8c26134478903f278ba5969581",
            "placeholder": "​",
            "style": "IPY_MODEL_4b4fcf2d383844e9ab220f902831a080",
            "value": "model.safetensors: 100%"
          }
        },
        "bbf0ae8c8d3649b38941fed8c0f044ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd5b6dc083740acb017b4261d7ea7b6",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c6fb89e7530417abebad5146baff495",
            "value": 90868376
          }
        },
        "1ad921c23417401b9e2eca55a81495d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3770c7043d43452593bef63c819f7f25",
            "placeholder": "​",
            "style": "IPY_MODEL_6fdbe20adf654a15b621e39f65132cfa",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 116MB/s]"
          }
        },
        "f6e29d143ad240c9b5e91dfcd776f0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3dbc8c26134478903f278ba5969581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b4fcf2d383844e9ab220f902831a080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd5b6dc083740acb017b4261d7ea7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6fb89e7530417abebad5146baff495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3770c7043d43452593bef63c819f7f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fdbe20adf654a15b621e39f65132cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29434d69c82b4dcbaef283ccc43ab4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da4d643edf2d46b3b28417607d49ba45",
              "IPY_MODEL_1b230be983a24395992605dee96d5e16",
              "IPY_MODEL_b68dd2ec48014dd7a7de746652b7550c"
            ],
            "layout": "IPY_MODEL_426a06952cc542d78f836935071eeb41"
          }
        },
        "da4d643edf2d46b3b28417607d49ba45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09eb7d64543c42b1b137b64391547630",
            "placeholder": "​",
            "style": "IPY_MODEL_a59c928c056a4691a5e2ad53852ba660",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1b230be983a24395992605dee96d5e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58d2fc976cef4129a530f32d4b4f5315",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26537e012e914db7b55f713074a47228",
            "value": 350
          }
        },
        "b68dd2ec48014dd7a7de746652b7550c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c41839bc143416bb84d07c605a86301",
            "placeholder": "​",
            "style": "IPY_MODEL_4bf46f7426d74d59ab2ae26d5f96bd22",
            "value": " 350/350 [00:00&lt;00:00, 31.4kB/s]"
          }
        },
        "426a06952cc542d78f836935071eeb41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09eb7d64543c42b1b137b64391547630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59c928c056a4691a5e2ad53852ba660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58d2fc976cef4129a530f32d4b4f5315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26537e012e914db7b55f713074a47228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c41839bc143416bb84d07c605a86301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf46f7426d74d59ab2ae26d5f96bd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c3e0010bec44ed48d2569e69d38e76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a4546392ce9406198dd2270bb67bf53",
              "IPY_MODEL_e8ccac5b329f4f14b3d3724776608e46",
              "IPY_MODEL_f2207aa17f2c46e18a591eee5839bba8"
            ],
            "layout": "IPY_MODEL_dd372803254248dfb4fc91a2ea18be7d"
          }
        },
        "3a4546392ce9406198dd2270bb67bf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7c809d98d64aedbb40444ca91aa0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_d2199340317e42bdb922d8204b07538f",
            "value": "vocab.txt: 100%"
          }
        },
        "e8ccac5b329f4f14b3d3724776608e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1fa98e22f945dba3f0e81dc47f2a58",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4817cb0de78d4283a16193d6fff3a184",
            "value": 231508
          }
        },
        "f2207aa17f2c46e18a591eee5839bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e62fa92fdb40e8933074c43423a4e8",
            "placeholder": "​",
            "style": "IPY_MODEL_37dc6b317a4045658a67d1c71b49ca73",
            "value": " 232k/232k [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "dd372803254248dfb4fc91a2ea18be7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7c809d98d64aedbb40444ca91aa0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2199340317e42bdb922d8204b07538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba1fa98e22f945dba3f0e81dc47f2a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4817cb0de78d4283a16193d6fff3a184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28e62fa92fdb40e8933074c43423a4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37dc6b317a4045658a67d1c71b49ca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe4371d847e4cc892c2e79131a18d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a66cbf1805f4ece9798c92feb7fa183",
              "IPY_MODEL_b4f94f933a28440589018a41017010f1",
              "IPY_MODEL_457aac78d3444613b2d8174914cdb513"
            ],
            "layout": "IPY_MODEL_1970d77f38624e11bf760c6ca79ff783"
          }
        },
        "5a66cbf1805f4ece9798c92feb7fa183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad5d9dbbd3f4f24876cda7e1b6e58f1",
            "placeholder": "​",
            "style": "IPY_MODEL_2a3fd3e58c2f4c5dadf92a7f90a9c024",
            "value": "tokenizer.json: 100%"
          }
        },
        "b4f94f933a28440589018a41017010f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7626778ceaaa4c7a9aeccf02d5cd3b00",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a445c372369a40c4985b9623ee6f3237",
            "value": 466247
          }
        },
        "457aac78d3444613b2d8174914cdb513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5259d6759fd74b01a055d068120417a7",
            "placeholder": "​",
            "style": "IPY_MODEL_0bfa85e3e6514083a6a38e331e42e1c8",
            "value": " 466k/466k [00:00&lt;00:00, 945kB/s]"
          }
        },
        "1970d77f38624e11bf760c6ca79ff783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad5d9dbbd3f4f24876cda7e1b6e58f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3fd3e58c2f4c5dadf92a7f90a9c024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7626778ceaaa4c7a9aeccf02d5cd3b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a445c372369a40c4985b9623ee6f3237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5259d6759fd74b01a055d068120417a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bfa85e3e6514083a6a38e331e42e1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "950a717ef4c34b8199006abf421d925b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c037e54c11544912b250562c2f7a380e",
              "IPY_MODEL_bb559a518f11432ab47ffc2fb2d03f31",
              "IPY_MODEL_4e7b3b2eb0684e83b5cb6fed88a8167e"
            ],
            "layout": "IPY_MODEL_35220d0360d4431aa7526cb66bbc1971"
          }
        },
        "c037e54c11544912b250562c2f7a380e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7219fb3d1642c59f82ca00e585277c",
            "placeholder": "​",
            "style": "IPY_MODEL_10003e117e774fd896696e78b4cbbdb5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bb559a518f11432ab47ffc2fb2d03f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab2024862524dfbae1130beb5c65d93",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b1ed6fc34804a48aaef671950717d22",
            "value": 112
          }
        },
        "4e7b3b2eb0684e83b5cb6fed88a8167e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b125fca97aa946d3aa73641b0531f5be",
            "placeholder": "​",
            "style": "IPY_MODEL_99925ef621444426833756b16d2633b9",
            "value": " 112/112 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "35220d0360d4431aa7526cb66bbc1971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7219fb3d1642c59f82ca00e585277c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10003e117e774fd896696e78b4cbbdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ab2024862524dfbae1130beb5c65d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1ed6fc34804a48aaef671950717d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b125fca97aa946d3aa73641b0531f5be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99925ef621444426833756b16d2633b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c5118cd008240eb8c83a1f5717052cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8b539150bdc4914b46839c8be1e0fcf",
              "IPY_MODEL_ccb6034bfa6b408197f1cb043251c914",
              "IPY_MODEL_7adb6ef654ec4129956d9b82df0d8420"
            ],
            "layout": "IPY_MODEL_3e40784a5f4747d19f4a52f70e6d0fef"
          }
        },
        "f8b539150bdc4914b46839c8be1e0fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c60f78720d452f9663c046ae2bd90f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb1969dfdbb74a76ae9645cf5a1c3e9b",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "ccb6034bfa6b408197f1cb043251c914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10a55ebf7884e9f8b3d091654cb7400",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592fac0758c941d08fa8d2722a19a15b",
            "value": 190
          }
        },
        "7adb6ef654ec4129956d9b82df0d8420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fef2ed8d34d4cc5b0c48fc1126ecf51",
            "placeholder": "​",
            "style": "IPY_MODEL_d69f8cbeb4fd465dba4ff51d8164ee79",
            "value": " 190/190 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "3e40784a5f4747d19f4a52f70e6d0fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c60f78720d452f9663c046ae2bd90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1969dfdbb74a76ae9645cf5a1c3e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d10a55ebf7884e9f8b3d091654cb7400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592fac0758c941d08fa8d2722a19a15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fef2ed8d34d4cc5b0c48fc1126ecf51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69f8cbeb4fd465dba4ff51d8164ee79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wVlSvPDBWSF",
        "outputId": "b6f7db50-e5d4-49c9-aabd-ac44c5b8ada3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install sentence-transformers\n",
        "!pip install streamlit\n",
        "!pip install streamlit-chat\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install huggingface-hub\n",
        "!pip install pypdf\n",
        "!pip install llama-cpp-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txc1fUi4BTRb",
        "outputId": "b8fed7a4-6fad-40c5-be5d-7b7bfeed50a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.51-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.46 langchain-text-splitters-0.0.1 langsmith-0.1.51 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.29.3\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.7.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.0b1-py2.py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.0b1 smmap-5.0.1 streamlit-1.33.0 watchdog-4.0.0\n",
            "Collecting streamlit-chat\n",
            "  Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-chat) (1.33.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-chat) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.9.0b1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (1.16.0)\n",
            "Installing collected packages: streamlit-chat\n",
            "Successfully installed streamlit-chat-0.1.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.65.tar.gz (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.65-cp310-cp310-linux_x86_64.whl size=3370960 sha256=5c4b85b42d120a7b8bd4bc6713b5b50719c96a3392bb3c2f6f79afca16049ff3\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/37/bf/f7c65dbafa5b3845795c23b6634863c1fdf0a9f40678de225e\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import os\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "-hJcbCRnvcdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_session_state():\n",
        "    session_state = {\n",
        "        \"history\": [],\n",
        "        \"generated\": [\"Hello! Ask me anything about 🤖\"],\n",
        "        \"past\": [\"Hey! 👋\"]\n",
        "    }\n",
        "    return session_state\n"
      ],
      "metadata": {
        "id": "qoc_B25FxlQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conversation_chat(query, chain, session_state):\n",
        "    result = chain({\"question\": query, \"chat_history\": session_state[\"history\"]})\n",
        "    session_state[\"history\"].append((query, result[\"answer\"]))\n",
        "    return result[\"answer\"]\n"
      ],
      "metadata": {
        "id": "Kin1WViBxyol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_user_questions():\n",
        "    questions = []\n",
        "    print(\"Enter your questions one by one and type 'done' when finished:\")\n",
        "    while True:\n",
        "        user_input = input(\"Enter your question: \")\n",
        "        if user_input.lower() == 'done':\n",
        "            break\n",
        "        questions.append(user_input)\n",
        "    return questions"
      ],
      "metadata": {
        "id": "3OGfkCoWBG5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_chat_history(chain, session_state):\n",
        "    questions = collect_user_questions()\n",
        "    for question in questions:\n",
        "        answer = conversation_chat(question, chain, session_state)\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\\n\")\n"
      ],
      "metadata": {
        "id": "8riu7D9lyEU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_conversational_chain(vector_store):\n",
        "    print('Creating conversational chain...')\n",
        "    print(\"Started creating LLM...\")\n",
        "\n",
        "    llm = LlamaCpp(\n",
        "        streaming=True,\n",
        "        model_path=\"/content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "        temperature=0.75,\n",
        "        top_p=1,\n",
        "        verbose=True,\n",
        "        n_ctx=4096,\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
        "        memory=memory,\n",
        "    )\n",
        "\n",
        "    print(\"Completed creating LLM!\")\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "s0HXc4A8yQMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    session_state=initialize_session_state()\n",
        "    print(\"ChatBot using Mistral-7B-Instruct LLM :books:\")\n",
        "\n",
        "    uploaded_files = [\"/content/Chainpoll A high efficacy method for LLM hallucination detection - 2310.18344.pdf\"]\n",
        "\n",
        "    if uploaded_files:\n",
        "        text = []\n",
        "        for file_path in uploaded_files:\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                file_contents = f.read()\n",
        "            file_extension = os.path.splitext(file_path)[1]\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "                temp_file.write(file_contents)\n",
        "                temp_file_path = temp_file.name\n",
        "                print(\"loading: \", file_path)\n",
        "            loader = None\n",
        "            if file_extension == \".pdf\":\n",
        "                loader = PyPDFLoader(temp_file_path)\n",
        "\n",
        "            if loader:\n",
        "                text.extend(loader.load())\n",
        "                os.remove(temp_file_path)\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=10000, chunk_overlap=20\n",
        "        )\n",
        "        text_chunks = text_splitter.split_documents(text)\n",
        "\n",
        "        print(\"chunks:\\n\", text_chunks)\n",
        "\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            model_kwargs={\"device\": \"cpu\"},\n",
        "        )\n",
        "\n",
        "        print(\"embeddings:\\n\", embeddings)\n",
        "\n",
        "        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n",
        "\n",
        "        chain = create_conversational_chain(vector_store)\n",
        "\n",
        "        display_chat_history(chain,session_state)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "526f72f8a762415386ee7f65b00e2220",
            "651976157e0b4affa9360df86c41e83e",
            "5216909494644f38ab3c2b7c19f7bd36",
            "1d5c03dcb07c45918057aea41f35b085",
            "88a93573daa949d0bf542ea7d0c3cd6f",
            "0c080aea91ca44b48623cdb97c319641",
            "eaeb9443ce3c40ec861c1f251b090f9a",
            "9d3e9013708c43b6b8f19cb98d3250b5",
            "556ade52b6a44cee8fa02713727116af",
            "6cdd902c9dae45daba00748b3be7afb6",
            "1633308f46974da79004a67f2aaf92cd",
            "b406cd9cc1b94d3aa7a4e8b5e885845e",
            "470c48fd14934b4fa6fb40902752a0d8",
            "8580e4d5529449968621615ba8aa0e23",
            "a476a1110fdd4b64b0634add1e42f5bd",
            "d981bd58d4c74ec489515234585a962d",
            "69a35c6356c74817a53a7fbff42dd9b0",
            "5659025d30b44ce696706836288318e8",
            "2431f19a166b49e4a4204ef904d3daf7",
            "8fbf251af2774b4eb11a2bd6da48b239",
            "9bc34ce12a4d4f7582a3fc0441b5fe63",
            "93d2e6725e7d49978d1114251827de9a",
            "9a8ea16c7f42450a8e7d6824ed59ff44",
            "a4169a801e0540b4a447814ee163f3a7",
            "fbb33b5232b2479195bd64bebf3f5540",
            "3d05d51e8f3b4c9e9c5d88ec975ef3ba",
            "53993729526e48749c36b928eb083dac",
            "7f3babdfcf2142b593364084295a08ed",
            "072996917f8a434e92a3f8de90e66d14",
            "bd50d7fa5a40489cbd60ef2eacf0e6b9",
            "646112f2138d40caa0223af726611ec3",
            "4743f2eca90346b0b91a55afb82c6a1f",
            "a682b9bf5d7446e79ad91e8ca0e7ee79",
            "3e50284106c44c269b6e6f641d0d507c",
            "6f31bf6b08d64c5ca5a6dd388ba129bd",
            "f19ef990430e49bab720d7d0494596e4",
            "b5c617d3bfd8498794866eb4f68d9924",
            "0283ea89785f4c289309bde22e4f6b83",
            "cb2ed41d669342c3860cb629a75a4653",
            "8b3b9ba6af664ae6b37c6398a2f6ef69",
            "7238e8d96a324a93b2eb81baa4a2ca5c",
            "c7461bb5edfe4c2d9f71c2d666603225",
            "3cfdc8d654434f8985b18e5ed5d838c3",
            "be87d5c28e104e17bcfa0a1014f07da2",
            "d0bf037b7ee44faaaff7d929ef86f53f",
            "1e3ce12f47224705bd340f2b32620787",
            "5ae694d8ea0f4af7b9f65aaccfb5f68c",
            "c98835d0cd8b44cc851ba8cb9049d471",
            "200986e6cb21406db5c47d22389debb3",
            "221d37413b984973a592449313440ea9",
            "82e3dd09ca3f4ccaa77ae07011f8c39e",
            "7b13904a0d9b4fd99170e3a8ef7f9159",
            "f45624075d1e43e1ad7bf44f3abdadf0",
            "52f8e8d06ee741c3ad5c9e9280465815",
            "533433ca6707490aa671a9b7d1f2c239",
            "6915cf41bd6a4ab7b03b00d59c028f44",
            "d917a1c5caaa41ea9d152ccd123e0fda",
            "bbf0ae8c8d3649b38941fed8c0f044ed",
            "1ad921c23417401b9e2eca55a81495d5",
            "f6e29d143ad240c9b5e91dfcd776f0b7",
            "fd3dbc8c26134478903f278ba5969581",
            "4b4fcf2d383844e9ab220f902831a080",
            "1dd5b6dc083740acb017b4261d7ea7b6",
            "2c6fb89e7530417abebad5146baff495",
            "3770c7043d43452593bef63c819f7f25",
            "6fdbe20adf654a15b621e39f65132cfa",
            "29434d69c82b4dcbaef283ccc43ab4c7",
            "da4d643edf2d46b3b28417607d49ba45",
            "1b230be983a24395992605dee96d5e16",
            "b68dd2ec48014dd7a7de746652b7550c",
            "426a06952cc542d78f836935071eeb41",
            "09eb7d64543c42b1b137b64391547630",
            "a59c928c056a4691a5e2ad53852ba660",
            "58d2fc976cef4129a530f32d4b4f5315",
            "26537e012e914db7b55f713074a47228",
            "6c41839bc143416bb84d07c605a86301",
            "4bf46f7426d74d59ab2ae26d5f96bd22",
            "3c3e0010bec44ed48d2569e69d38e76a",
            "3a4546392ce9406198dd2270bb67bf53",
            "e8ccac5b329f4f14b3d3724776608e46",
            "f2207aa17f2c46e18a591eee5839bba8",
            "dd372803254248dfb4fc91a2ea18be7d",
            "ae7c809d98d64aedbb40444ca91aa0b3",
            "d2199340317e42bdb922d8204b07538f",
            "ba1fa98e22f945dba3f0e81dc47f2a58",
            "4817cb0de78d4283a16193d6fff3a184",
            "28e62fa92fdb40e8933074c43423a4e8",
            "37dc6b317a4045658a67d1c71b49ca73",
            "4fe4371d847e4cc892c2e79131a18d70",
            "5a66cbf1805f4ece9798c92feb7fa183",
            "b4f94f933a28440589018a41017010f1",
            "457aac78d3444613b2d8174914cdb513",
            "1970d77f38624e11bf760c6ca79ff783",
            "7ad5d9dbbd3f4f24876cda7e1b6e58f1",
            "2a3fd3e58c2f4c5dadf92a7f90a9c024",
            "7626778ceaaa4c7a9aeccf02d5cd3b00",
            "a445c372369a40c4985b9623ee6f3237",
            "5259d6759fd74b01a055d068120417a7",
            "0bfa85e3e6514083a6a38e331e42e1c8",
            "950a717ef4c34b8199006abf421d925b",
            "c037e54c11544912b250562c2f7a380e",
            "bb559a518f11432ab47ffc2fb2d03f31",
            "4e7b3b2eb0684e83b5cb6fed88a8167e",
            "35220d0360d4431aa7526cb66bbc1971",
            "9e7219fb3d1642c59f82ca00e585277c",
            "10003e117e774fd896696e78b4cbbdb5",
            "0ab2024862524dfbae1130beb5c65d93",
            "1b1ed6fc34804a48aaef671950717d22",
            "b125fca97aa946d3aa73641b0531f5be",
            "99925ef621444426833756b16d2633b9",
            "9c5118cd008240eb8c83a1f5717052cf",
            "f8b539150bdc4914b46839c8be1e0fcf",
            "ccb6034bfa6b408197f1cb043251c914",
            "7adb6ef654ec4129956d9b82df0d8420",
            "3e40784a5f4747d19f4a52f70e6d0fef",
            "b5c60f78720d452f9663c046ae2bd90f",
            "fb1969dfdbb74a76ae9645cf5a1c3e9b",
            "d10a55ebf7884e9f8b3d091654cb7400",
            "592fac0758c941d08fa8d2722a19a15b",
            "7fef2ed8d34d4cc5b0c48fc1126ecf51",
            "d69f8cbeb4fd465dba4ff51d8164ee79"
          ]
        },
        "outputId": "cb2f8dbe-281f-422f-bf24-c2d42f3c7b25",
        "id": "fH2OBuVUxnpH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatBot using Mistral-7B-Instruct LLM :books:\n",
            "loading:  /content/Chainpoll A high efficacy method for LLM hallucination detection - 2310.18344.pdf\n",
            "chunks:\n",
            " [Document(page_content='ChainPoll : A H IGHEFFICACY METHOD FOR LLM\\nHALLUCINATION DETECTION\\nRobert Friel\\nGalileo Technologies Inc.Atindriyo Sanyal\\nGalileo Technologies Inc.\\nOctober 31, 2023\\nABSTRACT\\nLarge language models (LLMs) have witnessed significant advancements in generating coherent, intelligent,\\nand contextually relevant responses. However, the presence of hallucinations – inaccurate or unmotivated\\nclaims – remains a persistent challenge, motivating the development of automated metrics for the detection of\\nhallucinations in LLM outputs.\\nWe make two contributions: ChainPoll , a novel hallucination detection methodology that substantially out-\\nperforms existing alternatives, and RealHall , a carefully curated suite of benchmark datasets for evaluating\\nhallucination detection metrics proposed in recent literature.\\nTo construct RealHall , we critically review tasks and datasets used in prior work on hallucination detection,\\nfinding that many of them have very limited relevance to the powerful LLMs used in practice today. To get rid\\nof this limitation, we select four datasets that are truly challenging for state-of-the-art (modern era) LLMs and\\nrelevant to real world applications.\\nWe use RealHall to perform a head-to-head and non-biased comparison between ChainPoll and a wide range of\\nhallucination metrics proposed in recent literature and showcase that ChainPoll achieves superior performance\\nacross all four of the benchmarks in RealHall , with an aggregate AUROC of 0.781, beating the next best\\ntheoretical algorithm by 11%, and beating industry standards for LLMs by over 23%, while simultaneously\\nbeing cheaper to compute and significantly more explainable than alternative metrics.\\nWe propose 2 new metrics to quantify LLM hallucinations - Adherence andCorrectness . The former pertinent to\\nRetrieval Augmented Generation (RAG) workflows measuring an LLM’s reasoning abilities within the provided\\ndocuments and context, while the latter focused capturing general logical and reasoning based mistakes.\\nContents\\n1 Introduction 2\\n1.1 Summary of contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.2 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n2 Problem statement 3\\n2.1 Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n3RealHall 4\\n3.1 RealHall datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.1.1 RealHall Closed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.1.2 RealHall Open . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n4 Metrics 6arXiv:2310.18344v1  [cs.CL]  22 Oct 2023', metadata={'source': '/tmp/tmpzih2wj99', 'page': 0}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n4.1 Metrics evaluated . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n4.1.1 BLEU, ROUGE, METEOR and similar metrics . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n4.2 Defining ChainPoll . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n4.2.1 ChainPoll-Correctness andChainPoll-Adherence . . . . . . . . . . . . . . . . . . . . . . . . 7\\n4.2.2 Re-using chains of thought for explainability . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n5 Results 8\\n5.1 AUROC scores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n5.2 Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n6 Related work 10\\n6.1 SelfCheckGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n6.2 G-Eval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n6.3 GPTScore . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n6.4 TRUE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n6.5 ChatProtect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n7 Conclusion 12\\nA Appendices 14\\nA.1 Dataset selection process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nA.1.1 Rejected datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nA.2 Model completions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nA.3 Data annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nA.4 Pseudo-entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\nA.4.1 Probability models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA.5 Evaluation details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA.6 SummEval case study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA.7 Detailed results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n1 Introduction\\n1.1 Summary of contributions\\nLarge language models (LLMs) have witnessed significant advancements in generating coherent, intelligent, and\\ncontextually relevant responses. However, the presence of hallucinations – inaccurate or unmotivated claims – remains\\na persistent challenge, motivating the development of automated metrics for the detection of hallucinations in LLM\\noutputs.\\nThis paper presents the research behind the Galileo platform’s state-of-the-art hallucination detection capabilities.\\nOur key contributions are\\n1.RealHall : a suite of four difficult, realistic benchmark datasets for evaluating hallucination detection\\nmethods.\\n•We developed RealHall by performing an extensive, careful review of academic papers and benchmarks\\non hallucination detection.\\n2', metadata={'source': '/tmp/tmpzih2wj99', 'page': 1}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n•We discovered that many of the datasets and benchmarks used to evaluate hallucination detection metrics\\nin past work are nearly irrelevant to practical users of today’s LLMs .\\n•LLMs have become much more powerful in just the past few years, and they’re being deployed for a\\ndiverse range of difficult use cases. Evaluation benchmarks for LLMs have not caught up with this rapid\\nprogress.\\n•We developed RealHall to close the gap between real LLM use and evaluation. RealHall gives us\\nconfidence that our experiment results will generalize to real use cases.\\n2.ChainPoll : a novel approach to hallucination detection that is substantially more accurate than any metric\\nwe’ve encountered in the academic literature.\\n•ChainPoll dramatically out-performs a range of published alternatives – including SelfCheckGPT\\n[1],GPTScore [2],G-Eval [3], and TRUE [4] – in a head-to-head comparison on RealHall .\\n•ChainPoll is also faster and more cost-effective than most of the metrics listed above.\\n•Though much of the research literature concentrates on the the easier case of closed-domain hallucination\\ndetection, we show that ChainPoll is equally strong when detecting either open-domain or closed-\\ndomain hallucinations.\\n–We develop versions of ChainPoll specialized to each of these cases: ChainPoll-Correctness for\\nopen-domain and ChainPoll-Adherence for closed-domain.\\n–The Correctness and Context Adherence metrics in the Galileo console are powered by\\nChainPoll-Correctness andChainPoll-Adherence , respectively.\\nMetric Aggregate AUROC\\nChainPoll 0.781\\nSelfCheck-Bertscore 0.673\\nSelfCheck-NGram 0.644\\nG-Eval 0.579\\nMax pseudo-entropy 0.550\\nGPTScore 0.524\\nRandom Guessing 0.500\\nTable 1: Hallucination detection performance on RealHall , averaged across datasets.\\n1.2 Organization\\nThe rest of the paper is organized as follows.\\n•Section 2 describes the problem we’re solving and outlines our basic methodology.\\n•Section 3 describes our critical review of existing datasets and benchmarks, and introduces our benchmark\\nsuite RealHall .\\n•Section 4 surveys the metrics we evaluated in our research, including our best-performing metric ChainPoll .\\n•Section 5 contains our experimental results.\\n•Section 6 reviews past work on hallucination detection metrics.\\n2 Problem statement\\nWe are interested in the following setting:\\n• We have a dataset of text inputs to a state-of-the-art generative LLM (large language model).\\n• We send the inputs to the LLM, and get back text completions , one for each input.\\n• We want to determine which of the completions, if any, contain hallucinations.\\n•We are interested in detecting both types of hallucination delineated in prior work [ 5]:open-domain and\\nclosed-domain .\\n–Open-domain hallucinations are false claims about the world made by the LLM.\\n3', metadata={'source': '/tmp/tmpzih2wj99', 'page': 2}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n–Closed-domain hallucinations involve the model straying from the context of a specific reference text,\\nsuch as a document to summarize.\\n•We want to identify hallucinations using one or more metric(s) that can be automatically computed, efficiently\\nand at low cost.\\n•In some cases, we may be querying the model through an API like OpenAI’s. This limits the available\\ninformation about it.\\n–We cannot use metrics that require access to model weights, activations, embeddings, or other information\\nthat would not be available through an API.\\n• Our metric should work well across a diverse range of tasks that are\\n–challenging enough to elicit frequent hallucinations, and\\n–relevant , in the sense of that they measure LLM capabilities that underlie practical use cases\\nThere are some important differences between the way we’ve framed the problem above, and the way it is typically\\nframed in the academic literature:\\n1.We have more exacting standards for quality. We require that our metrics perform well across a range of\\ndifferent tasks – not just one or two – and we require that these tasks are both challenging andrelevant .\\n2.Academic hallucination benchmarks are typically built around responses from older models that are much\\nweaker than modern LLMs (e.g. [ 6,7,8]). These models often hallucinate in extreme ways that are relatively\\neasy to detect. We seek metrics that can detect the subtler hallucinations produced by modern LLMs.\\n3.Although much of the academic literature (e.g. [ 3,4,9]) focuses solely closed-domain hallucination, we also\\naim to detect open-domain hallucinations.\\n4.We aim to create practical methods that can be deployed as part of a product while maintaining a fast, fluid\\nuser experience. Some metrics in the academic literature can take hours to compute over a full dataset, even\\nwith a very powerful GPU; we require our metrics to be much more efficient than this.\\n2.1 Approach\\nWe treat hallucination detection as a binary classification problem. For our purposes, a metric for hallucination detection\\nis a binary classifier which outputs a scalar score1.\\nTo assess the performance of our metrics, we constructed four benchmark datasets , which we collectively call RealHall\\n(Section 3).\\nBy a benchmark dataset , we mean a list of prompts, completions and ground-truth boolean labels indicating whether\\neach completion contained hallucination(s).\\nWe use RealHall to evaluate a variety of metrics (Section 4), covering a range of different approaches proposed in prior\\nwork as well as our own novel metrics like ChainPoll .\\n3RealHall\\nRealHall is a new benchmark suite for evaluating hallucination detection metrics, built on the guiding principles of\\nChallenge ,Realism , and Task Diversity (Table 2).\\nTo build RealHall , we conducted an extensive survey of available datasets, applying the rubric given in Table 2.\\nCriterion Description\\nChallengeThe LLM is asked to perform a task that is challenging, even for today’s\\nstate-of-the-art LLMs.\\nRealism The task is relevant to practical use cases.\\nTask DiversityTaken as a whole, the benchmark suite should assess a wide range of dif-\\nferent LLM capabilities.\\nTable 2: Criteria we applied when reviewing datasets.\\n1We do not assume that these scalar scores are probabilities, merely that they are ordered, with larger values indicating a\\nhigher likelihood of the positive class (hallucination).\\n4', metadata={'source': '/tmp/tmpzih2wj99', 'page': 3}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nMost of the datasets we reviewed did not meet our bar for Challenge ,Realism , and/or Task Diversity . Most notably, we\\nfound that many benchmarks used in prior work on hallucination detection were deficient in one of more of these\\naspects .\\nThis observation is alarming, as it suggests that published evaluation results in this field do not provide reliable guidance\\nabout which metrics will perform well in real, practical use.\\nWe created RealHall to remedy this defect in past evaluations. RealHall contains four datasets carefully selected for\\nChallenge ,Realism , and Task Diversity .\\nFor details on the process of constructing RealHall , see Appendix A.1.\\n3.1 RealHall datasets\\nRealHall contains four datasets, divided into two groups of two: RealHall Closed andRealHall Open .\\n•RealHall Closed evaluates how well a metric can detect closed-domain hallucinations : inconsistency between\\nthe generated text and a reference text provided in the prompt.\\n•RealHall Open evaluates how well a metric can detect open-domain hallucinations : false claims about the real\\nworld.\\n3.1.1 RealHall Closed\\nRealHall Closed contains the datasets COVID-QA with retrieval andDROP .\\n•COVID-QA with retrieval .\\n–COVID-QA [ 10] is a dataset containing question-answer pairs about Covid-19, constructed by biomedical\\nexperiments.\\n–We construct a RAG-like dataset from COVID-QA, following the approach in [ 11]. We build a vector\\nstore over the 250k-passage reference corpus from [ 11], using OpenAI API embeddings. During inference,\\nwe and retrieve the top k= 4passages and present them alongside the question. (We use these retrieved\\ndocuments instead of the original reference documents packaged with COVID-QA.2)\\n–COVID-QA with retrieval is a realistic test of a metric’s ability to detect closed-domain hallucinations in\\nRetrieval Augmented Generation (RAG) use cases. It is moderately challenging for SOTA LLMs.\\n•DROP .\\n–DROP [ 12] is an open-book QA dataset containing questions that require discrete reasoning over multiple\\nfacts mentioned in a passage (for example, locating two numbers in the passage, then subtracting one\\nfrom the other).\\n–DROP is challenging for SOTA LLMs. We included it in RealHall alongside COVID-QA because it\\nassesses a distinct, and more challenging, notion of consistency with the provided documents3.\\n3.1.2 RealHall Open\\nRealHall Open contains the datasets Open Assistant prompts andTriviaQA .\\n•Open Assistant prompts .\\n–The Open Assistant dataset [ 13] contains dialog trees solicited as training data for a ChatGPT-like\\nassistant.\\n–We used only the initial prompts, i.e. the first turn of each dialog tree.\\n–We judged these prompts to be a good test bed for eliciting open-domain hallucinations: they cover a\\ndiverse range of tasks and subject matter, they are often challenging even for SOTA LLMs, and they\\nare more representative of the way LLMs are prompted in practice than the prompts found in large\\ninstruction-tuning datasets.\\n•TriviaQA .\\n2We retrieved documents from a vector store, rather than using the documents provided with the dataset, to mimic the RAG\\nuse case as closely as possible.\\n3Evaluating consistency for DROP requires discrete reasoning, for the same reason that answering DROP questions requires\\ndiscrete reasoning.\\n5', metadata={'source': '/tmp/tmpzih2wj99', 'page': 4}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n–TriviaQA [14] contains question-answer pairs written by trivia enthusiasts.\\n–TriviaQA was originally proposed as a reading comprehension benchmark, with reference documents\\nprovided to the model. However, recent works (e.g. [ 15]) tend to use the questions alone, without the\\ndocuments, to probe LLMs for factual knowledge.\\n–We follow this line of work and present TriviaQA questions alone. TriviaQA in this format is challenging\\nfor SOTA LLMs, and we judged it to be a useful supplement to the signal we get from benchmarking\\nmetrics against Open Assistant prompts, focusing in on the LLM’s ability to faithfully recall declarative\\nknowledge.\\n4 Metrics\\n4.1 Metrics evaluated\\nWe benchmarked ChainPoll against a wide range of other metrics from the literature on LLM hallucinations:\\n•ChainPoll without detailed CoT.\\n–This metric combines the same aggregation method as ChainPoll (Section 4.2) with a “vanilla” chain-of-\\nthought prompt, while ChainPoll uses a more carefully engineered prompt we call “detailed CoT.”\\n• G-Eval-3.54\\n• GPTScore\\n• SelfCheck-BertScore\\n• SelfCheck-NGram\\n• TRUE (closed-domain only)\\nSee Section 6 for descriptions of these metrics, and Table 5 for details on why we excluded some metrics from our\\nevaluations.\\nWe also include a simple probability-based baseline, following prior work (e.g. [1]).\\nFor our probability-based baseline, we use a metric we call pseudo-entropy : an approximation to the Shannon entropy,\\nadapted to settings like the OpenAI API in which only a subset of probabilities are available. We found that pseudo-\\nentropy performed best across a range of probability-based metrics we investigated.\\nFor a full description of pseudo-entropy, see Appendix A.4.\\n4.1.1 BLEU, ROUGE, METEOR and similar metrics\\nWe chose not to benchmark any metrics that compare the LLM’s completion with a ground-truth response . This\\ncategory includes BLEU, ROUGE, and METEOR.\\nMetrics that require a ground-truth response cannot adequately serve the full range of hallucination-detection needs that\\nLLM users face. While ground-truth responses may be available for some users in some parts of the LLM workflow,\\nthey are notreliably available in key scenarios like\\n•Monitoring : an LLM application in production must respond to arbitrary user input. It’s impossible to prepare\\na ground-truth response in advance for every possible input the user could send to the system.\\n•Rapid experimentation : it’s often unclear what LLMs are and aren’t capable of, and users may want to rapidly\\n“try out” many different hypothetical tasks for the LLM. Producing prompts for a novel task is much faster and\\neasier than producing ground-truth responses, especially in creatively defined tasks where it’s not clear at the\\noutset what the correct response should be.\\n4.2 Defining ChainPoll\\nAcross all datasets, our best-performing metrics use the approach we call ChainPoll .\\nTo compute these metrics, we take the following steps:\\n4Referred to as simply “G-Eval” below for simplicity.\\n6', metadata={'source': '/tmp/tmpzih2wj99', 'page': 5}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n1.Ask gpt-3.5-turbo whether the completion contained hallucination(s), using a detailed and carefully\\nengineered prompt.\\n2. Run step 1 multiple times, typically 5. (We use batch inference here for its speed and cost advantages.)\\n3.Divide the number of \"yes\" answers from step 2 by the total number of answers to produce a score between 0\\nand 1.\\nAmong metrics previously proposed in the literature, ChainPoll is perhaps closest to G-Eval [3].\\nHowever, we find that ChainPoll dramatically outperforms G-Eval across the entirety of RealHall . We attribute this to a\\nnumber of key differences between ChainPoll and G-Eval:\\n•We put considerable effort into prompt engineering. In particular, we phrase our chain-of-thought prompt in a\\nway that reliably elicits a very specific and systematic explanation from the model, an prompting approach we\\ncall “detailed CoT.”\\n–By contrast, the prompts used in [ 3] either did not use chain-of-thought, or asked for the answer before the\\nchain-of-thought explanation, which prevents the answer from leveraging the reasoning in the explanation.\\n•We request boolean judgments, rather than numeric scores. In early experiments on this distinction, we\\nobserved that boolean judgments work better than scores, even when eliciting only a single completion.\\n• We use gpt-3.5-turbo , while [3] used either text-davinci-003 orgpt-45.\\n4.2.1 ChainPoll-Correctness andChainPoll-Adherence\\nDepending on the situation, a user may want to detect open-domain hallucinations, closed-domain hallucinations, or\\nboth.\\nWe define a ChainPoll -based metric for each of these cases.\\n•ChainPoll-Correctness uses ChainPoll to detect open-domain hallucination.\\n•ChainPoll-Adherence uses ChainPoll to detect open-domain hallucination.\\nThe two metrics differ only in the prompt format used when prompting gpt-3.5-turbo . InChainPoll-Correctness ,\\nthe prompt format asks the model to look for open-domain hallucinations; in ChainPoll-Adherence , the prompt format\\nasks the model to look for closed-domain hallucinations.\\n4.2.2 Re-using chains of thought for explainability\\nIn the ChainPoll approach, the LLM is asked to judge whether or not the original completion contained hallucination,\\njustifying its answer with a chain-of-thought (CoT) explanation. While we use CoT primarily as a means to improve the\\nquality of the model’s final judgements, it also opens up interesting avenues for explaining that judgment to an end user.\\nThat is, we can re-use the CoT text generated by the model as a justification for the judgment that the completion did, or\\ndid not, contain hallucination(s)6.\\nWe find that the chains of thought written by gpt-3.5-turbo are coherent and frequently convincing. An example is\\ngiven below, explaining why a COVID-QA completion was hallucinated:\\nThe response claims that the study described is a descriptive study of severe\\nhospitalized cases of laboratory-confirmed influenza during five epidemic seasons\\n(2010–2015).\\n5While GPT-4 performs very well at hallucination detection, we consider it too expensive for routine use in production. Our\\ngoal is here to offer high quality hallucination detection without the expense of GPT-4. (OpenAI’s pricing is such that aggregating\\nover multiple gpt-3.5-turbo completions is still much cheaper than generating a single completion with GPT-4.)\\n6An interesting line of recent work has called into question whether model-generated chains of thought faithfully reflect the\\nmodel’s actual reasoning process [ 16]. From our perspective, this does not reduce the value of model-generated chains of thought\\nas user-facing justifications for model-generated judgments.\\nFor example, suppose the model tells us that a particular completion was hallucinated, and it provides a CoT consistent with this\\njudgment. Whether or not the CoT reflects how the model actually arrived at its judgment, it is nonetheless an argument that could\\nbe made in favor of that judgment. If the argument is correct, then it has value for the end user, even if the model arrived at its\\n(correct) judgment through some other reasoning process.\\n7', metadata={'source': '/tmp/tmpzih2wj99', 'page': 6}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nTo verify whether this claim is supported by the documents, we need to check if any\\nof the documents mention a study or research that matches the description.\\nThe first document mentions the need to deepen knowledge of the effect of aging,\\nchronic diseases, and immune response in order to implement preventive measures.\\nThis document does not directly state that it describes a study of severe\\nhospitalized cases of laboratory-confirmed influenza.\\nThe second document does not provide any relevant information to support or refute\\nthe claim.\\nThe third and fourth documents both mention a study design and protocol for\\ninvestigating social network patterns and respiratory disease transmission and\\ncontrol. These documents do not mention severe cases of laboratory-confirmed\\ninfluenza.\\nBased on the analysis of the documents, none of them provide direct support for the\\nclaim that the study described is a descriptive study of severe hospitalized cases\\nof laboratory-confirmed influenza during five epidemic seasons (2010–2015).\\nTherefore, the response is not supported by the documents.\\n5 Results\\nWe present the results of our evaluations here, demonstrating that ChainPoll is a new state-of-the-art.\\nAcross a diverse range of benchmark tasks, the ChainPoll outperforms all other methods – in most cases, by a huge\\nmargin.\\nTaking efficiency into account ChainPoll ’s lead is even larger. It outperforms the next-best method, SelfCheck-BertScore,\\nwhile using only 1/4 as much LLM inference, and without using an additional model like BERT.\\nUnlike all other methods considered here, ChainPoll also provides human-readable verbal justifications for the judgments\\nit makes, via the chain-of-thought text produced during inference.\\n5.1 AUROC scores\\nMetric Average AUROC\\nChainPoll-Correctness 0.772\\nSelfCheck-Bertscore 0.670\\nSelfCheck-NGram 0.636\\nG-Eval 0.574\\nMax pseudo-entropy 0.565\\nGPTScore 0.489\\nRandom Guessing 0.500\\nTable 3: Open-domain hallucination detection performance on RealHall Open , averaged across datasets.\\nMetric Average AUROC\\nChainPoll-Adherence 0.789\\nSelfCheck-Bertscore 0.675\\nSelfCheck-NGram 0.652\\nTRUE 0.593\\nG-Eval 0.584\\nMax pseudo-entropy 0.535\\nGPTScore 0.558\\nRandom Guessing 0.500\\nTable 4: Closed-domain hallucination detection performance on RealHall Closed , averaged across datasets.\\nPer-dataset AUROC scores are provided in Appendix A.7.\\n8', metadata={'source': '/tmp/tmpzih2wj99', 'page': 7}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n5.2 Plots\\nFigure 1: ROC curves for hallucination detection across RealHall datasets. The ChainPoll curves are ChainPoll-\\nCorrectness in the top row, and Chainpoll-Adherence in the bottom row.\\n9', metadata={'source': '/tmp/tmpzih2wj99', 'page': 8}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nFigure 2: Precision-recall curves for hallucination detection across RealHall datasets. The ChainPoll curves are\\nChainPoll-Correctness in the top row, and Chainpoll-Adherence in the bottom row.\\n6 Related work\\nThe field of LLM hallucination detection is relatively new, as LLMs themselves are relatively new.\\nRather than giving a complete historical review of this field, we will cover the specific metrics that we deemed most\\npromising when reviewing the literature.\\nTable 5 provides a summary view of these metrics, comparing and contrasting them to our best-performing metric,\\nChainPoll .\\n10', metadata={'source': '/tmp/tmpzih2wj99', 'page': 9}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nMetric Description Tested against ∗ TypeaCost/exbBatchcGPU-\\nfreedQuality\\nvs\\nourse\\nChainPoll\\n(ours)Prompting +\\naggregationRealHall OC 5 ✓ ✓ 100%\\nSelfCheck-\\nBertScore [1]Sentence-level\\nrerun checkingWikipedia arti-\\nclesO >20 ✓ 63%\\nSelfCheck-\\nNGram [1]Sentence-level\\nrerun checkingWikipedia arti-\\nclesO 20 ✓ ✓ 52%\\nTRUE NLI [4] NLIVarious (closed-\\ndomain)C ≤1 ✓ 33%h\\nG-Eval-3.5f[3]Prompting +\\naggregationSummEval, Top-\\nicalChatC 20 ✓ ✓ 29%\\nGPTScore [2]Prompting +\\nperplexityVarious (closed-\\ndomain)C ≤1 ✓ ✓ 9%\\nSelfCheck-\\nMQAG [1]Sentence-level\\nrerun checkingWikipedia arti-\\nclesO >20 N/Ag\\nChatProtect\\n[17]Sentence-level\\nrerun checkingWikipedia arti-\\nclesO 2/sentence ✓ N/Ag\\nTable 5: How our metrics compare to others in the literature.∗This column lists the evaluation data used to test the\\nquality of the metric in the original publication introducing it. In this paper, we independently evaluate all metrics\\nonRealHall .aO = open-domain, C = closed-domain, OC = both open-domain and closed-domainbAn estimate of\\nhow compute-intensive the metric is, in units of additional LLM-generated responses required during evaluation of\\na single response. > N denotes a metric which generates Ncompletions and then does additional computation with\\na neural model.cWhether the computations noted in the Cost/ex column can be computed in parallel. In practice,\\nbatch metrics are much faster than sequential metrics, even if they require more computation per example.dWhether\\nthe metric can be served without the added expense of a dedicated GPU.eAverage (AUROC score minus 0.5) over\\ndatasets in RealHall , as a fraction of ChainPoll ’s performance. We subtract 0.5 to normalize scores because an\\nAUROC score of 0.5 corresponds to random guessing.fWe do not benchmark G-Eval-4, as it does not meet our bar\\nfor cost (it is 20x as expensive as the already-expensive GPT-4).gWe did not benchmark these metrics, as their high\\ncompute intensity and sequential nature do not meet our bar for efficiency.hClosed-domain tasks only, as TRUE\\nNLI cannot be applied in open-domain tasks.\\n6.1 SelfCheckGPT\\nSelfCheckGPT [ 1] proposed an approach based on checking the self-consistency between an LLM response and a large\\nnumber of additional responses, sampled from the same LLM using the same prompt. For their main experiments, the\\nauthors used 20 additional responses per evaluated response.\\nThe authors introduced three metrics using this approach, which differ in the way they compute agreement between\\nresponses.\\n•SelfCheck-BertScore computes agreement using BertScore [18].\\n•SelfCheck-NGram computes agreement by fitting a simple unigram7language model and using its probabilities\\non the original response.\\n•SelfCheck-MQAG computes agreement using a MQAG [ 19], a complex question-answering pipeline using four\\nfine-tuned neural models. The pipeline generates multiple-choice questions based on the original response,\\nthen tries to answer them using only the additional responses.\\nNotably, the SelfCheckGPT metrics were proposed as sentence-level metrics, requiring computation of agreement\\nscores separately for each sentence in the response – which can be computationally expensive for long responses. (This\\nexpense combines with the expense of generating a potentially large number of additional responses.)\\nTo compute response-level aggregates, the scores for sentences are averaged.\\nThe SelfCheckGPT metrics were evaluated on a dataset of 238 prompts written by the authors, all of which ask the\\nmodel to write a Wikipedia page for a specific person. We critically assess this dataset in Section A.1.1.\\n7The authors experimented with different gram lengths, finding that unigrams worked best.\\n11', metadata={'source': '/tmp/tmpzih2wj99', 'page': 10}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n6.2 G-Eval\\nG-Eval [ 3] propose an approach that evaluates an LLM response by asking an LLM8to rate the response on a 1-5 scale,\\nwith provided guidelines.\\nThe LLM’s probabilities of outputting the tokens ’ 1’, ’ 2’, etc. are used to produce a weighted-average rating.\\nWhen probabilities are not available, the authors sample from the LLM 20 times and average the ratings over this\\nsample.\\nG-Eval was evaluated on two closed-domain datasets, SummEval and TopicalChat. We critically assess these datasets\\nin Section A.1.1, with further analysis in Appendix A.6.\\n6.3 GPTScore\\nGPTScore [ 2] uses a simple method which evaluates an LLM response by prepending a instruction (e.g. “write a\\nfactually consistent summary”) to the prompt and response, then evaluating the perplexity of the response using an\\nLLM9.\\nGPTScore was evaluated on a large number of closed-domain datasets, such as SummEval.\\nWe reproduce GPTScore’s strong performance on SummEval (Appendix A.6), yet we find that it performs very poorly\\nonRealHall .\\nWe hypothesize that this discrepancy results from the following:\\n•We find that the prefix adds little value: we can achieve nearly identical performance on SummEval by simply\\ncomputing perplexity on the original response.\\n•We analyze the strong performance of perplexity on SummEval, finding that it results from a mismatch between\\nthe (weaker) models used to generate responses in SummEval and the (stronger) models used to compute\\nperplexity.\\n•When a strong, modern LLM is used both to generate responses and to compute perplexity, the strong\\nperformance of perplexity (and thus GPTScore) disappears.\\n6.4 TRUE\\nTRUE [ 4] builds a benchmark suite of 11 closed-domain datasets, covering similar ground to the evaluation datasets\\nused in GPTScore [4].\\nThe authors compare a number of different metrics on these datasets. Their best-performing metric used probabilities\\nfrom a T5-XXL model finetuned for natural language inference (NLI).\\nIn conjunction with the paper, the authors released the weights of a model similar to this one, though trained on a\\ndifferent data mixture. We compute scores using the released model, and refer to this metric as TRUE NLI .\\n6.5 ChatProtect\\nChatProtect [17] proposes an approach similar to SelfCheckGPT [1].\\nLike SelfCheckGPT, ChatProtect works on the sentence level, and uses self-consistency between multiple responses to\\ndetect hallucinations.\\nWhereas SelfCheckGPT generates alternatives at the response , ChatProtect generates a separate alternative version of\\neach sentence in context, and checks each one for consistency against the original sentence.\\n7 Conclusion\\nHallucinations are possibly the single largest impediment to widespread practical use of LLMs. This fact means there is\\na pressing need to identify ways of automatically discovering hallucinations in LLM outputs.\\n8Either a different LLM, or the same one.\\n9As in G-Eval, this may be a different LLM, or the same one.\\n12', metadata={'source': '/tmp/tmpzih2wj99', 'page': 11}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nWe have developed a benchmark suite, RealHall , for evaluating these hallucination detection metrics. Notably, we find\\nthat many tasks and datasets used in past work have minimal relevance to practical use of SOTA LLMs. Our benchmark\\nsuite focuses in on four practically relevant tasks on which even today’s powerful LLMs hallucinate with alarming\\nfrequency.\\nWe use our benchmark suite to evaluate a variety of metrics for open-domain and closed-domain hallucination detection\\n– including a new metric, ChainPoll , which outperforms all other metrics considered, while being efficient to compute\\nand inherently explainable.\\nReferences\\n[1]Potsawee Manakul, Adian Liusie, and Mark J. F. Gales. Selfcheckgpt: Zero-resource black-box hallucination\\ndetection for generative large language models, 2023.\\n[2] Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. Gptscore: Evaluate as you desire, 2023.\\n[3]Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. G-eval: Nlg evaluation\\nusing gpt-4 with better human alignment, 2023.\\n[4]Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas\\nScialom, Idan Szpektor, Avinatan Hassidim, and Yossi Matias. True: Re-evaluating factual consistency evaluation,\\n2022.\\n[5] OpenAI. Gpt-4 technical report. 2023.\\n[6]Alexander R. Fabbri, Wojciech Kry ´sci´nski, Bryan McCann, Caiming Xiong, Richard Socher, and Dragomir Radev.\\nSummeval: Re-evaluating summarization evaluation, 2021.\\n[7]Alex Wang, Kyunghyun Cho, and Mike Lewis. Asking and answering questions to evaluate the factual consistency\\nof summaries, 2020.\\n[8]Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter. Evaluating attribution in dialogue systems: The\\nbegin benchmark, 2022.\\n[9]Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, and Jiawei Han.\\nTowards a unified multi-dimensional evaluator for text generation, 2022.\\n[10] Timo Möller, Anthony Reina, Raghavan Jayakumar, and Malte Pietsch. COVID-QA: A question answering\\ndataset for COVID-19. In Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020 , Online, July 2020.\\nAssociation for Computational Linguistics. URL https://aclanthology.org/2020.nlpcovid19-acl.18 .\\n[11] Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kaluarachchi, Rajib Rana, and Suranga\\nNanayakkara. Improving the domain adaptation of retrieval augmented generation (rag) models for open domain\\nquestion answering, 2022.\\n[12] Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. Drop: A\\nreading comprehension benchmark requiring discrete reasoning over paragraphs, 2019.\\n[13] Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah\\nBarhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, Shahul ES, Sameer Suri, David Glushkov, Arnav\\nDantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. Openassistant\\nconversations – democratizing large language model alignment. 2023.\\n[14] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised\\nchallenge dataset for reading comprehension, 2017.\\n[15] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov,\\nSoumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya\\nChen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao,\\nVedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas,\\nViktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux,\\nThibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar\\nMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan\\nSchelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor,\\nAdina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie\\nKambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2:\\nOpen foundation and fine-tuned chat models, 2023.\\n13', metadata={'source': '/tmp/tmpzih2wj99', 'page': 12}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n[16] Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li,\\nEsin Durmus, Evan Hubinger, Jackson Kernion, Kamil ˙e Lukoši ¯ut˙e, Karina Nguyen, Newton Cheng, Nicholas\\nJoseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam McCandlish, Sandipan Kundu, Saurav Kadavath,\\nShannon Yang, Thomas Henighan, Timothy Maxwell, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-\\nDodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman, and Ethan Perez. Measuring faithfulness in chain-of-\\nthought reasoning, 2023.\\n[17] Niels Mündler, Jingxuan He, Slobodan Jenko, and Martin Vechev. Self-contradictory hallucinations of large\\nlanguage models: Evaluation, detection and mitigation, 2023.\\n[18] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evaluating text\\ngeneration with bert, 2020.\\n[19] Potsawee Manakul, Adian Liusie, and Mark J. F. Gales. Mqag: Multiple-choice question answering and generation\\nfor assessing information consistency in summarization, 2023.\\n[20] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh\\nHajishirzi. Self-instruct: Aligning language models with self-generated instructions, 2023.\\n[21] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar,\\nArjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis,\\nHaizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel,\\nKuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza,\\nPulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra,\\nSujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh\\nHajishirzi, and Daniel Khashabi. Super-naturalinstructions: Generalization via declarative instructions on 1600+\\nnlp tasks, 2022.\\n[22] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V . Le, Barret\\nZoph, Jason Wei, and Adam Roberts. The flan collection: Designing data and methods for effective instruction\\ntuning, 2023.\\n[23] Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. Halueval: A large-scale hallucination\\nevaluation benchmark for large language models, 2023.\\n[24] Tomáš Ko ˇciský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward\\nGrefenstette. The narrativeqa reading comprehension challenge, 2017.\\n[25] Michael Völske, Martin Potthast, Shahbaz Syed, and Benno Stein. TL;DR: Mining Reddit to learn automatic\\nsummarization. In Proceedings of the Workshop on New Frontiers in Summarization , pages 59–63, Copenhagen,\\nDenmark, September 2017. Association for Computational Linguistics. doi:10.18653/v1/W17-4508. URL\\nhttps://aclanthology.org/W17-4508 .\\n[26] Arman Cohan, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli\\nGoharian. A discourse-aware attention model for abstractive summarization of long documents. In Proceedings of\\nthe 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, Volume 2 (Short Papers) , pages 615–621, New Orleans, Louisiana, June 2018. Association\\nfor Computational Linguistics. doi:10.18653/v1/N18-2097. URL https://aclanthology.org/N18-2097 .\\n[27] Chenguang Zhu, Yang Liu, Jie Mei, and Michael Zeng. Mediasum: A large-scale media interview dataset for\\ndialogue summarization, 2021.\\n[28] Derek Tam, Anisha Mascarenhas, Shiyue Zhang, Sarah Kwan, Mohit Bansal, and Colin Raffel. Evaluating the\\nfactual consistency of large language models through summarization, 2022.\\n[29] Shiqi Chen, Siyang Gao, and Junxian He. Evaluating factual consistency of summaries with large language\\nmodels, 2023.\\n[30] Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey\\nHsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang,\\nKevin Wang, and Andy Zou. A framework for few-shot language model evaluation, September 2021. URL\\nhttps://doi.org/10.5281/zenodo.5371628 .\\nA Appendices\\nA.1 Dataset selection process\\nTable 6 lists all the datasets we reviewed during the development of RealHall .\\n14', metadata={'source': '/tmp/tmpzih2wj99', 'page': 13}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nA.1.1 covers the datasets we reviewed but did not include in RealHall .\\nA.3 describes our process for assigning ground-truth labels to the benchmark data.\\nDataset Description Type* NotesIncluded\\ninReal-\\nHall\\nOpen Assistant Prompts\\n[13]Prompts for an LLM assis-\\ntantO ✓\\nTriviaQA [14]General knowledge ques-\\ntionsO† ✓\\nSelf-Instruct Human Eval\\n[20]Prompts for an LLM assis-\\ntantOLess challenging than\\nOpen Assistant\\nSuper-NaturalInstructions\\n[21]Instruction tuning data O, CNot reflective of practical\\nLLM use\\nFLAN [22] Instruction tuning data O, CNot reflective of practical\\nLLM use\\nSelfCheckGPT Wikibio\\n[1]Prompts of the form\\n“write a Wikipedia arti-\\ncle about X”ONarrow task, memoriza-\\ntion concerns\\nHaluEval [23]Prompts and completions\\nwith synthetic hallucina-\\ntionO, CNot representative of natu-\\nrally arising hallucination\\nCOVID-QA [ 10] with\\nretrieval [11]Covid-19 knowledge ques-\\ntionsC ✓\\nDROP [12]Discrete reasoning ques-\\ntionsC ✓\\nNarrativeQA [24]Reading comprehension\\nquestionsCNoisy labels, easy for\\nSOTA LLMs\\nSummEval [6]News summarization\\nprompts and completionsC See Section A.1.1.2\\nTL;DR [25]Reddit summarization\\nprompts and completionsC See Section A.1.1.2\\nArXiV Summarization\\n[26]Scientific paper summa-\\nrization promptsC See Section A.1.1.2\\nMediaSum [27]Interview summarization\\npromptsC See Section A.1.1.2\\nBEGIN [8]Knowledge-conditioned\\ndialogueC See Section A.1.1.3\\nTable 6: Datasets reviewed during benchmark construction. * O = open-domain, C = closed-domain †We present\\nTriviaQA questions on their own, without reference documents.\\nA.1.1 Rejected datasets\\nWe distilled RealHall from a long list of candidate datasets by applying the rubric given in Table ??.\\nMost of the datasets we considered did not meet this bar. Here, we detail the reasons behind our choice not to include\\nvarious datasets in RealHall .\\nA.1.1.1 Instruction tuning datasets. Instruction tuning datasets, such as Super-NaturalInstructions [ 21] and FLAN\\n[22], were ruled out by our second criterion: The tasks and prompts should be reflective of real LLM use “in the wild” .\\nWhile these datasets work well as training data for instruction-tuning an LLM, we concluded that they are not well\\nrepresentative of the way users interact with instruction-tuned LLMs in practice.\\nTo illustrate this claim, consider two selected instructions from\\nSuper-NaturalInstructions:\\n•“Generate a question, given a collection of facts. ”\\n15', metadata={'source': '/tmp/tmpzih2wj99', 'page': 14}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n•“Given premise, initial context with ending, and new counterfactual ending, generate counterfactual context\\nwhich supports the new story ending. ”\\nHighly artificial, structured tasks like this may be helpful if you want to train an LLM to understand instructions, but\\nthey bear little resemblance to the tasks and instructions seen during practical LLM use.\\nA.1.1.2 Summarization datasets. In the academic literature, the summarization datasets Summeval [ 6] and QAGS\\n[7] are often10used to evaluate metrics for closed-domain hallucination detection.\\nThese datasets share the following key features:\\n1. They consist of\\n•documents from a standard summarization dataset, e.g. CNN/DM, together with\\n• model-written summaries of these documents, and\\n• human annotations assessing the quality of the summaries\\n2. The models used to generate for the model-written summaries are much weaker than current SOTA LLMs.\\nThese datasets are easy to use as hallucination benchmarks, because they come packaged with human annotations (point\\n1).\\nHowever, because the summaries packaged with these datasets were produced by much weaker models than modern\\nLLMs (point 2), these datasets do not reflect the distribution of hallucination-like behaviors observed with today’s\\nSOTA LLMs during practical use.\\nOur experiments show that modern SOTA LLMs hallucinate much less often in summarization tasks than the older\\nmodels used in Summeval and QAGS.\\nFor example, as assessed by GPT-411,\\n• 20% of the summaries in Summeval contain hallucination(s)\\n•when ChatGPT12is asked to summarize the same set of documents, only 3% of the summaries contain\\nhallucination(s)\\nWe observed a similarly low rate of hallucination on many other summarization datasets, including TL;DR, ArXiv\\nSummarization, and MediaSum.\\nWe conclude that summarization is “too easy” for SOTA LLMs to make it a good benchmark for hallucination detection;\\nwhile these models still hallucinate occasionally in summarization, they do it infrequently enough that a large amount of\\ndata would be necessary to distinguish signal from noise when making comparisons between metrics. Thus, we focus\\non other tasks that SOTA LLMs find more difficult.\\nGiven the popularity of SummEval as a benchmark, we include SummEval evaluations in an Appendix (A.6), though\\nwe do not include it in RealHall .\\nA.1.1.3 Other rejected datasets. This section covers our reasons for rejecting other datasets that do not fall under\\nthe broad themes covered in A.1.1.1 and A.1.1.2.\\n•BEGIN, introduced in [ 8], contains model-written responses generated for three dialogue datasets (WOW,\\nTopicalChat and CMU) from four models.\\n–We did not include this dataset because the models (e.g. GPT-2, CTRL) are much weaker than today’s\\nLLMs.\\n–We ran a small experiment benchmarking some metrics on the TopicalChat subset of BEGIN, and found\\nsimilar trends to those observed in Appendix A.6, e.g. the anomalously strong performance of perplexity.\\n•SelfCheckGPT Wikibio, introduced in [ 1], contains model-written imitations of biographical Wikipedia papers,\\nlabeled for factual accuracy at the sentence level.\\n10For example, Summeval was used in this fashion in [3, 4, 9, 28, 29].\\n11See Section A.3 for more on our use of GPT-4.\\n12Unless otherwise noted, we use the terms “ChatGPT” and gpt-3.5-turbo interchangeably. Although matches common\\npractice, we clarify it explicitly here because the ChatGPT product includes a GPT-4 option for paid subscription users.\\n16', metadata={'source': '/tmp/tmpzih2wj99', 'page': 15}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\n–We did not include this dataset because of its narrow scope, and because we noticed a number of\\nverbatim-memorized Wikipedia pages among the non-hallucinated examples.13\\n•HaluEval [ 23] contains several datasets. With the exception of the “general” set, each HaluEval set contains a\\nmixture of (1) “clean” ChatGPT completions generated in the ordinary manner, and (2) synthetic hallucinations,\\ni.e. hallucinated completions generated by explicitly asking ChatGPT to hallucinate.\\n–We did not include this dataset because we concluded that the synthetic hallucinations were not a\\nrepresentative proxy of “real” hallucinations produced naturally during ChatGPT inference.\\n–For example, on the HaluEval QA dataset, the synthetic-hallucination answers were typically much longer\\nthan the “clean” answers. (The average character lengths were 66 and 14, respectively; 90% of the “clean”\\nanswers were under 25 characters, yet the same is true for 5% of the synthetic-hallucination answers.) It\\nwould be trivial to design a metric that could distinguish these two types of answers, but this “success”\\nwould not transfer to the case of real, naturally occurring hallucinations.\\n•NarrativeQA [ 24] contains reading comprehension questions based on stories (books or film scripts). Following\\ncommon practice, we used the summaries included in NarrativeQA as reference documents, rather than the\\nmuch longer original texts.\\n–We did not include this dataset for a combination of reasons.\\n–During initial testing, we found that GPT-4 marked 8% of ChatGPT-generated answers as hallucinated,\\nwhile marking 12% of ground truth answers as hallucinated (!). Digging in further, we discovered that\\nNarrativeQA questions are often ill-posed – the answer is not available in the summary14.\\n–Most of the hallucinations in the ChatGPT data occurred when the question was ill-posed. Ignoring these\\ncases, ChatGPT almost never hallucinated on NarrativeQA. We conclude that this task is too easy to\\nmake a good benchmark for our purposes.\\nA.2 Model completions\\nAfter selecting datasets for our benchmarks, we generated completions for each example in each benchmark using an\\nLLM from the OpenAI API.\\nWe used gpt-3.5-turbo , commonly known as ChatGPT, to generate completions in most of our experiments. In an\\nearly set of experiments on the Open Assistant Prompts dataset, we also experimented with text-davinci-003 as the\\ncompletion model.\\nWhen necessary, we wrote simple prompt formats (e.g. ’Answer the question, using the documents.\\n{question} {documents}’ ) to communicate the task to the model.\\nA.3 Data annotation\\nWe assigned a boolean ground-truth label to each (prompt, completion) pair: 1 if the completion contained any\\nhallucination(s), 0 otherwise.\\nTo produce these labels, we used a mixture of human annotation, GPT-4 annotation, and automatic rule-based scoring.\\nOur earliest experiments used human annotations on the Open Assistant dataset. Concurrently with this early work, we\\nconstructed a carefully engineered prompt for GPT-4 which asked it to determine whether a completion from another\\nmodel contained hallucination(s).\\nWe found that GPT-4 performed extremely well as an annotator, in the sense that it agreed very closely with the\\njudgments of our human annotators. In fact, GPT-4 disagreed with our human annotators no more often than the human\\nannotators disagreed with one another.\\nEncouraged by this result, we used GPT-4 as the sole annotator for several of the datasets considered here, specifically\\nCOVID-QA and TriviaQA.\\n13Although memorized content repeated by LLMs is often factually accurate, it is atypical of LLM-generated content, and\\nmay provide misleading signals about which metrics work well in the general case. Memorized text can often be detected\\nthrough its anomalously high model likelihood. Thus, when the hallucinated/not-hallucinated distinction is confounded by the\\nmemorized/not-memorized distinction, the hallucination detection performance of likelihood-based methods will be overesti-\\nmated.\\n14The questions were written on the basis of the summaries alone, so using summaries rather than full texts does not account\\nfor this issue.\\n17', metadata={'source': '/tmp/tmpzih2wj99', 'page': 16}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nThe DROP dataset is conventionally evaluated using a bag-of-words-based F1 score. We used this score to assign\\nground-truth labels for DROP, since we observed that it produced very similar results to GPT-4 while being faster to\\ncompute.15\\nA.4 Pseudo-entropy\\nThe OpenAI API only provides probabilities for a subset of possible tokens at each position. The model’s full vocabulary\\ncovers tens of thousands of tokens, but the API only provides probabilities for 5 or 616.\\nLetNbe the size of the full vocabulary, and Mbe the number of tokens for which probability data is available through\\nthe API, where M≪N. Letpibe the probability of the ith token. Without loss of generality, suppose the tokens are\\nordered so that the Mtokens with API-supplied probabilities appear first.\\nThe Shannon entropy of the distribution is\\nS=NX\\ni=1pilog (pi) (1)\\nbut we cannot compute this exactly because pM+1, . . . , p Nare unavailable.\\nPPL5, introduced in [ 1], makes the following approximation in this case. Let ˜pibe the probability obtained by\\nnormalizing the top Mprobabilities so they sum to one17:\\n˜pi=−piPM\\ni=1pi(2)\\nThen PPL5 is the Shannon entropy, computed with ˜piinstead of pi:\\nPPL5 =−NX\\ni=1˜plog (˜p) (3)\\nConsider the case in which most of the probability mass lies outside the top Mtokens. In this case, the true Shannon\\nentropy will be large (all else being equal), since the distribution is spread out over many outcomes. However, the\\nnormalization in (2) removes all information about the amount of mass contained in the rest of the distribution, causing\\nPPL5 to ignore this information and yielding an undesirably low estimate of the entropy.\\nTo remedy this defect, we introduce a variant we call pseudo-entropy :\\nPseudo-entropy =−NX\\ni=1˜plog (p) (4)\\nThe difference lies in the use of p, rather than the normalized ˜pi, in the log-probability term.\\nWhen the distribution is spread out, the Mvalues of piwill be relatively low, and this fact will propagate through this\\nterm to yield a lower estimate of the entropy, as desired.\\nGalileo’s Uncertainty Score is a transformed version of the pseudo-entropy. Specifically, we use a scaled and shifted\\nexpit transform to convert the pseudo-entropy into a probability, setting the scale and shift constants so that it is an\\nunbiased predictor of ground-truth hallucination on our Open Assistant Prompts benchmark.\\n15We usedlm-eval-harness [30] to compute DROP F1 scores. To convert these to boolean labels, we marked scores of 0\\nas hallucinated, and any score above 0 as not hallucinated. Thresholding at zero yielded better agreement with GPT-4 than other\\nthresholds we tried.\\n16The API returns the probability of the sampled token, as well as the probability of the top 5 most likely tokens. Thus it\\nreturns 5 probabilities if the sampled token is in the top 5, and 6 otherwise.\\n17Equivalently, by applying a softmax operation to the top Mlog probabilities.\\n18', metadata={'source': '/tmp/tmpzih2wj99', 'page': 17}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nA.4.1 Probability models\\nInterestingly, we found that the performance of probability-based metrics is not strongly dependent on the model used\\nto produce the token probabilities.\\nThe OpenAI API does not return token probabilities for gpt-3.5-turbo at this time, so when it is the completion\\nmodel, we must use a different model as the probability model.\\nIn our experiments, we observed comparable performance across the probability models text-curie-001 ,\\ntext-davinci-003 , and the recently introduced davinci-002 , despite the different in size between the former\\nand the latter two. The pseudo-entropy scores reported here were computed using text-curie-001 .\\nA.5 Evaluation details\\nWhen computing metrics from past work, we used the code, models and prompts released by the original authors\\nwherever possible.\\nIn the case of G-Eval and GPTScore, the prompts included in the original work were specialized to particular tasks (e.g.\\nsummarization), and would be inapplicable for some of the tasks included in RealHall . To handle these cases, we wrote\\nlightly-adapted versions of the original prompts that replaced task-specific references with appropriate ones for the task\\nbeing considered (e.g. QA).\\nWhen computing G-Eval, we used gpt-3.5-turbo , where the original paper used the now-deprecated\\ntext-davinci-003 . The former is generally considered a stronger model than the latter, so we expect this to\\nwork in G-Eval’s favor.\\nWhen computing GPTScore, we use probabilities from text-curie-001 . The original paper computed probabilities\\nwith many models and did not make an overall recommendation, though they noted that larger models weren’t\\nnecessarily better. Our internal tests show that, across all probability-based methods we’ve tried, text-curie-001\\nworks as well or better than most OpenAI models.\\nA.6 SummEval case study\\nWe evaluated a subset of metrics on SummEval, and present results in Table A.6. All results here were reproduced\\nindependently.\\nAs in earlier work, we present correlation coefficients between metrics and human-annotated scores. We only consider\\nthe human-annotated Consistency score, as this is the score that captures closed-domain hallucination.\\nMetric ρ τ\\ntext-curie-001 Perplexity 0.458 0.364\\nGPTScore 0.460 0.366\\nChainPoll-Adherence 0.427 0.383\\nUniEval [9] 0.441 0.354\\nG-Eval 0.309 0.252\\nTable 7: Spearman ρand Kendall τcorrelations between metrics and human-annotated Consistency on SummEval.\\nOur results here reproduce the strong performance for GPTScore reported in the original paper [2].\\nAt first glance, this is puzzling, since we GPTScore performed poorly on RealHall . What accounts for the discrepancy?\\nTo answer the question, we begin by noting that we can match GPTScore’s performance simply by computing the\\nperplexity of the completion given the prompt, without GPTScore’s added prefix.\\nThis suggests that the strong performance of GPTScore on SummEval results from perplexity, rather than the prefix.\\nWhy would perplexity perform so well on SummEval, while failing on RealHall (as evidenced by our GPTScore results\\nonRealHall )? Figure 3 outlines our diagnosis.\\n19', metadata={'source': '/tmp/tmpzih2wj99', 'page': 18}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nFigure 3: Blue: Fraction of responses from each SummEval model receiving Consistency scores less than the maxi-\\nmum of 5.0. Red: Average text-curie-001 perplexity of each SummEval model.\\nSummEval contains responses from 24 models. All of these are weaker that today’s SOTA LLMs, and some are much\\nweaker, generating nearly incoherent text.\\nA large fraction of the responses that receive a less-than-perfect Consistency score come from a small subset of these\\nunder-performing models, such as M11.\\nBecause modern LLMs are much better at generating coherent text, they assign high perplexity (low likelihood) to the\\nincoherent text generated by these models. “Detecting hallucination” in this case only requires being able to distinguish\\nvery low-quality text – text that a modern LLM would be very unlikely to generate .\\nTo further illustrate the point, we include three example summaries from M11, the model at the left end of Figure 3.\\nIt should go without saying that this type of material bears no resemblance to the much subtler cases of hallucination\\nwe need to today with today’s LLMs:\\nvideo game “ space invaders ” was developed in japan back in 1970 . the classic\\nvideo game is the latest in the u.s.-based wwe . the is the of the new japan pro\\nwrestling organization . the “ classic game ” has been in japan ’s upper house for\\na second stint in politics in 2013 . the former is the founder of new japan ’s new\\njapan .\\ndonald sterling , nba team last year . sterling ’s wife sued for $ 2.6 million\\nin gifts . sterling says he is the former female companion who has lost the .\\nsterling has ordered v. stiviano to pay back $ 2.6 m in gifts after his wife sued .\\nsterling also includes a $ 391 easter bunny costume , $ 299 and a $ 299 .\\nfoxes host swansea on saturday just three points from the premier league . nigel\\npearson has urged leicester to keep their cool and ignore their relegation rivals .\\njamie vardy scored an injury-time winner against west bromwich albion on saturday .\\nthe foxes host the foxes at west brom in sunday .\\n20', metadata={'source': '/tmp/tmpzih2wj99', 'page': 19}), Document(page_content='ChainPoll : A High Efficacy Method for LLM Hallucination Detection\\nA.7 Detailed results\\nMetric AUROC\\nChainPoll-Correctness 0.697\\nChainPoll-Correctness (w/o detailed CoT) 0.629\\nSelfCheck-Bertscore 0.555\\nSelfCheck-NGram 0.516\\nG-Eval 0.533\\nMax pseudo-entropy 0.520\\nGPTScore 0.487\\nRandom Guessing 0.500\\nTable 8: AUROC scores for open-domain hallucination detection on Open Assistant Prompts.\\nMetric AUROC\\nChainPoll-Correctness 0.847\\nChainPoll-Correctness (w/o detailed CoT) 0.818\\nSelfCheck-Bertscore 0.784\\nSelfCheck-NGram 0.757\\nG-Eval 0.615\\nMax pseudo-entropy 0.611\\nGPTScore 0.492\\nRandom Guessing 0.500\\nTable 9: AUROC scores for open-domain hallucination detection on TriviaQA.\\nMetric AUROC\\nChainPoll-Adherence 0.785\\nChainPoll-Adherence (w/o detailed CoT) 0.707\\nSelfCheck-Bertscore 0.686\\nSelfCheck-NGram 0.581\\nTRUE 0.727\\nG-Eval 0.650\\nMax pseudo-entropy 0.552\\nGPTScore 0.622\\nRandom Guessing 0.500\\nTable 10: AUROC scores for closed-domain hallucination detection on CovidQA.\\nMetric AUROC\\nChainPoll-Adherence 0.794\\nChainPoll-Adherence (w/o detailed CoT) 0.537\\nSelfCheck-Bertscore 0.665\\nSelfCheck-NGram 0.722\\nTRUE 0.459\\nG-Eval 0.517\\nMax pseudo-entropy 0.519\\nGPTScore 0.494\\nRandom Guessing 0.500\\nTable 11: AUROC scores for closed-domain hallucination detection on DROP. The dramatic gap between the Chain-\\nPoll and ChainPoll (without detailed CoT) reflects chain-of-thought prompting on discrete reasoning tasks.\\n21', metadata={'source': '/tmp/tmpzih2wj99', 'page': 20})]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "526f72f8a762415386ee7f65b00e2220"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b406cd9cc1b94d3aa7a4e8b5e885845e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a8ea16c7f42450a8e7d6824ed59ff44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e50284106c44c269b6e6f641d0d507c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0bf037b7ee44faaaff7d929ef86f53f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6915cf41bd6a4ab7b03b00d59c028f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29434d69c82b4dcbaef283ccc43ab4c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c3e0010bec44ed48d2569e69d38e76a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe4371d847e4cc892c2e79131a18d70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "950a717ef4c34b8199006abf421d925b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c5118cd008240eb8c83a1f5717052cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings:\n",
            " client=SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ") model_name='sentence-transformers/all-MiniLM-L6-v2' cache_folder=None model_kwargs={'device': 'cpu'} encode_kwargs={} multi_process=False show_progress=False\n",
            "Creating conversational chain...\n",
            "Started creating LLM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
            ".................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 8\n",
            "llama_new_context_with_model: n_ubatch   = 8\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.63 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LAMMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed creating LLM!\n",
            "Enter your questions one by one and type 'done' when finished:\n",
            "Enter your question: What is the significance of ChainPoll achieving superior performance across all four benchmarks in RealHall?\n",
            "Enter your question: How does RealHall address the limitations of existing datasets used in prior work on hallucination detection?\n",
            "Enter your question: What are the key contributions of ChainPoll in the field of hallucination detection for LLMs?\n",
            "Enter your question: Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "\n",
            "llama_print_timings:        load time =     850.28 ms\n",
            "llama_print_timings:      sample time =      40.35 ms /    74 runs   (    0.55 ms per token,  1834.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =  279752.85 ms /  1992 tokens (  140.44 ms per token,     7.12 tokens per second)\n",
            "llama_print_timings:        eval time =   14691.45 ms /    74 runs   (  198.53 ms per token,     5.04 tokens per second)\n",
            "llama_print_timings:       total time =  295338.41 ms /  2066 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of ChainPoll achieving superior performance across all four benchmarks in RealHall?\n",
            "Answer:  The significance of ChainPoll achieving superior performance across all four benchmarks in RealHall is that it demonstrates the effectiveness of the method for detecting both open-domain and closed-domain hallucinations. It also highlights the importance of carefully engineering prompts for hallucination detection, as well as the value of Boolean judgments over numeric scores.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     850.28 ms\n",
            "llama_print_timings:      sample time =      14.06 ms /    26 runs   (    0.54 ms per token,  1848.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =   20482.22 ms /   168 tokens (  121.92 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4901.41 ms /    25 runs   (  196.06 ms per token,     5.10 tokens per second)\n",
            "llama_print_timings:       total time =   25525.85 ms /   193 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     850.28 ms\n",
            "llama_print_timings:      sample time =      77.08 ms /   138 runs   (    0.56 ms per token,  1790.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =  231663.20 ms /  1686 tokens (  137.40 ms per token,     7.28 tokens per second)\n",
            "llama_print_timings:        eval time =   27041.36 ms /   137 runs   (  197.38 ms per token,     5.07 tokens per second)\n",
            "llama_print_timings:       total time =  259733.30 ms /  1823 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does RealHall address the limitations of existing datasets used in prior work on hallucination detection?\n",
            "Answer:   Limitations of existing datasets in prior work on hallucination detection include lack of diversity, challenge, and realism. RealHall addresses these limitations by carefully selecting four datasets that meet criteria for Challenge, Realism, and Task Diversity. For example, RealHall Closed evaluates how well a metric can detect closed-domain hallucinations in Retrieval Augmented Generation (RAG) use cases by using COVID-QA with retrieval and DROP. RealHall Open evaluates how well a metric can detect open-domain hallucinations in realistic settings by using the Open Assistant prompts and TriviaQA datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     850.28 ms\n",
            "llama_print_timings:      sample time =      14.84 ms /    26 runs   (    0.57 ms per token,  1752.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =   43756.84 ms /   334 tokens (  131.01 ms per token,     7.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4943.24 ms /    25 runs   (  197.73 ms per token,     5.06 tokens per second)\n",
            "llama_print_timings:       total time =   48893.82 ms /   359 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     850.28 ms\n",
            "llama_print_timings:      sample time =      64.00 ms /   113 runs   (    0.57 ms per token,  1765.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =  232252.50 ms /  1686 tokens (  137.75 ms per token,     7.26 tokens per second)\n",
            "llama_print_timings:        eval time =   22547.03 ms /   112 runs   (  201.31 ms per token,     4.97 tokens per second)\n",
            "llama_print_timings:       total time =  255760.80 ms /  1798 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the key contributions of ChainPoll in the field of hallucination detection for LLMs?\n",
            "Answer:   The main limitations of existing datasets used in prior work on hallucination detection are that they do not meet the criteria for challenge, realism, and task diversity. RealHall addresses these limitations by carefully selecting four datasets that meet these criteria and dividing them into two groups of two: RealHall Closed and RealHall Open. The former evaluates how well a metric can detect closed-domain hallucinations while the latter tests open-domain hallucinations. This allows for more comprehensive evaluation of metrics in real-world use cases.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}